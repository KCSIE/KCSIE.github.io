---
title: Distributed Hash Table - 2 (Kademlia version)
tags: DHT BitTorrent IPFS P2P Blockchain Network
---

# About Kademlia

Kademlia is a distributed hash table designed by Petar Maymounkov and David Mazières in 2002. It was proposed in [*Kademlia: A Peer-to-peer information system based on the XOR Metric*](http://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf). It specifies the structure of the network and the exchange of information through node lookups. Kademlia nodes communicate among themselves using UDP. A virtual or overlay network is formed by the participant nodes. Each node is identified by a number or node ID. The node ID serves not only as identification, but the Kademlia algorithm uses the node ID to locate values (usually file hashes or keywords). In fact, the node ID provides a direct map to file hashes and that node stores information on where to obtain the file or resource.

When searching for some value, the algorithm needs to know the associated key and explores the network in several steps. Each step will find nodes that are closer to the key until the contacted node returns the value or no more closer nodes are found. This is very efficient: like many other DHTs, Kademlia contacts only O(log(n)) nodes during the search out of a total of n nodes in the system.

Kademlia will be abbreviated as Kad in the latter part, while the specific implementation will take Mainline DHT in BitTorrent, a kind of Kad algorithm, as an example.

# 关于Kademlia

Kademlia是由Petar Maymounkov和David Mazières在2002年设计的分布式哈希表，它在[《Kademlia: A Peer-to-peer information system based on the XOR Metric》](http://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf)中被提出。它规定了网络的结构和通过节点查找进行的信息交互。Kademlia节点之间使用UDP进行通信，参与者的节点形成了一个虚拟或覆盖网络，每个节点都由一个数字或节点ID来识别。节点ID不仅可以作为标识，而且Kademlia算法使用节点ID来定位值（通常是文件哈希值或关键词）。事实上，节点ID提供了一个与文件哈希值的直接映射，该节点存储了在哪里获得文件或资源的信息。

当我们在网络中搜索某些值(即通常搜索存储文件散列或关键词的节点)的时候，Kademlia算法需要知道与这些值相关的键，然后分步在网络中开始搜索。每一步都会找到一些节点，这些节点的ID与键更为接近，如果有节点直接返回搜索的值或者再也无法找到与键更为接近的节点ID的时候搜索便会停止。这种搜索值的方法是非常高效的，与其他的分散式杂凑表的实现类似，在一个包含n个节点的系统的值的搜索中，Kademlia仅访问O(log(n))个节点。

在后文中将Kademlia简称为Kad，同时具体实现将以Kad算法的一种BT协议中的Mainline DHT为例。

# Structure

## Keywords

### Node ID

In P2P networks, nodes are identified by a unique ID, which in the original Kad algorithm uses a 160-bit hash space as the Node ID.

Kademlia uses SHA1 hash to calculate Node ID, SHA1 is a 160 bit hash space, the whole ID length is 160 bits, that is 20 bytes, so it can hold 2^160 nodes. IPFS uses SHA256 to calculate Node ID, the ID length is 256 bit hash space, that is 32 bytes. Ethereum uses SHA3, which is also a 256-bit hash space of 32 bytes.

### Node Distance

Each node keeps information about its own neighborhood. In Kademlia, the node-to-node distance is not the physical distance, but the logical distance obtained by the XOR operation.

### XOR

The XOR operation is a bitwise operation that calculates the distance between two nodes. The smaller the result of XOR, the closer the distance is, usually in combination with prefix matching.

XOR means different is true and the same is false, with the symbol ⊕, and has the following characteristics.

- (A ⊕ B) == (B ⊕ A): XOR conforms to the "exchange law" and has symmetry. the distance between A and B is the same from any node, in contrast to Chord's distance algorithm, which is not symmetric.
- (A ⊕ A) == 0: transitivity, distance between self and self is zero.
- (A ⊕ B) > 0: The distance between two different keys must be greater than zero.
- (A ⊕ B) + (B ⊕ C) >= (A ⊕ C): trigonometric inequality, the distance from A to C through B is always greater than the distance from A to C directly.

For example, 0010 ⊕ 0000 = 0010,  0111 ⊕ 0010 = 0101.

### K-Bucket

Use a K-bucket to keep a list of all nodes that are within a certain distance from the current node, bucket0, bucket1, bucket2 ... bucketN record [1, 2), [2, 4), [4, 8), ... [2^i, 2^(i+1)).

### Routing Table

The routing table records all K-buckets, each K-bucket is limited to hold up to k nodes.

## Specific Structure

### Binary Trees

In Kademlia, Kad maps Node IDs (Keys) to a binary tree, and each Node ID (Key) is a leaf of this binary tree.

Mapping rules.

- The Node ID (Key) is represented in binary form, and then processed in order from the high bit to the low bit
- The nth bit of the binary corresponds to the nth level of the binary tree
- If the bit is 1, it goes to the left subtree, and if it is 0, it goes to the right subtree (artificial agreement, can be changed)
- After all the bits are processed, the Node ID corresponds to a leaf in the binary tree

### Distance and XOR

In Kademlia, a binary tree is built based on the number of prefix bits that match the Node ID of the current node and the Node IDs of other peer nodes it keeps, where the number of prefix bits matched is also called LCP (Longest Common Prefix). For example, if the current node is 1101, the LCP is 1 if it does not match from the second bit after the highest bit of the prefix matching with 1000. Each LCP of the current node is a subtree. Obviously, if two nodes share fewer ancestor nodes (with different high bits), they are far apart; conversely, if they share more ancestor nodes (with the same high bits), they are close together.

Suppose the current node ID is 0011, which can be divided into 4 subtrees with LCP = 3(none/), 2(0/), 1(00/), 0(001/).

[![RXD7Zt.md.png](https://z3.ax1x.com/2021/07/08/RXD7Zt.md.png)](https://imgtu.com/i/RXD7Zt)

For any given node, we divide the binary tree from the root node continuously down into a series of subtrees that do not contain that node. The highest subtree consists of half of the binary tree that does not contain that node, the next subtree consists of the remaining half of the tree that does not contain that node. If the height of this binary tree is m + 1, we will get m subtrees.

### K-Bucket and Routing Table

Each subtree is a K bucket, for a 160 bit space Node ID there are 160 subtrees in total i.e. 160 K buckets, (parameter Keyspace = 160 bit). Each K-bucket can be indexed by the result of XOR. The number of leaf nodes contained in a subtree is set to a maximum of k, k is the number of nodes that can be stored in each K-bucket (Usually, k = 20. It's 8 in Mainline DHT).

[![RXfT10.png](https://z3.ax1x.com/2021/07/08/RXfT10.png)](https://imgtu.com/i/RXfT10)

K nodes are taken in each subtree to form m K-buckets, and these m K-buckets are the routing table. We define the node obtained in the smallest subtree as the 0th k-bucket, the node obtained in the next smallest subtree as the 1st k-bucket, and so on. For each 0⩽i<m, the distance between the node in the i-th k-bucket and the current node is always within the interval [2^i, 2^(i+1)). Taking the K-bucket of node 101 at m = 3, k = 2 as an example：

[![RX6vt0.md.png](https://z3.ax1x.com/2021/07/08/RX6vt0.md.png)](https://imgtu.com/i/RX6vt0)

The following figure is another example:

[![RXRHCq.png](https://z3.ax1x.com/2021/07/08/RXRHCq.png)](https://imgtu.com/i/RXRHCq)

For Node 0010, the Node 0000 procedure is as follows:

- Distance = 0010 ⊕ 0000 = 0010 = 2
- The distance is in the interval [2^i, 2^(i+1)) (i = 1), i.e. 2 to 3, so Node 0000 should be placed in K-bucket1

It can also be determined by LCP and the highest non-zero bit of the result of XOR:

- 0011 and 0010, the first 3 bits match, the highest non-zero bit of XOR result is 0, put it in bucket 0
- 0000/0001 and 0010, the first 2 bits match, the highest non-zero bit of XOR result is 1, put it in bucket 1
- 0100/0110/0101/0111 and 0010, the first 1 bits match, the highest non-zero bit of XOR result is 0, put it in bucket 2

# 结构

## 关键词

### Node ID

在 P2P 网络中， 节点是通过唯一 ID 来进行标识的，在原始的 Kad 算法中，使用 160-bit 哈希空间来作为 Node ID。

Kademlia 中使用 SHA1 哈希来计算 Node ID，SHA1 是一个 160 bit 的哈希空间，整个 ID 长度是 160 个位， 也就是 20 个字节，这样可以容纳2^160个节点。IPFS 中都使用 SHA256 来计算 Node ID，ID 长度是 256 位的哈希空间， 也即 32 个字节。Ethereum 使用 SHA3，也是 256 位哈希空间， 32 字节。

### 距离

每个节点保存着自己附近节点的信息，在 Kademlia 中节点到节点的距离不是指物理距离，而是指通过异或运算得到的逻辑距离。

### 异或运算

异或运算即XOR，是一种位运算，用于计算两个节点之间距离的远近。把两个节点的 Node ID 进行 XOR 运算，XOR 的结果越小，表示距离越近，通常会结合前缀匹配来看。

XOR指异为真同为假，符号为⊕，具有如下特点：

- (A ⊕ B) == (B ⊕ A): XOR 符合“交换律”，具备对称性。A和B的距离从哪一个节点计算都是相同的，相比之下，Chord 的距离算法不对称。
- (A ⊕ A) == 0: 反身性，自己和自己的距离为零。
- (A ⊕ B) > 0: 两个不同的 key 之间的距离必大于零。
- (A ⊕ B) + (B ⊕ C) >= (A ⊕ C): 三角不等式, A经过B到C的距离总是大于A直接到C的距离。

比如：0010 ⊕ 0000 = 0010，0111 ⊕ 0010 = 0101。

对于每个节点，给的一个距离d， 至多有一个与其距离为d节点。这样Kademlia的拓扑结构是单向的， 单向性确保不管查找从哪个节点开始, 同一Key的所有查找都会沿着同一路径收敛。

### K桶

用一个K桶来保存与当前节点距离在某个范围内的所有节点列表，bucket0, bucket1, bucket2 ... bucketN 分别记录[1, 2), [2, 4), [4, 8), ... [2^i, 2^(i+1)) 范围内的节点列表。

### 路由表

路由表记录了所有K桶，每个K桶限制最多保存 k 个节点。

## 具体结构

### 二叉树

Kademlia 中，Kad把Node ID（Key）映射到一个二叉树，每一个Node ID（Key）都是这个二叉树的叶子。

映射规则：

- 将Node ID（Key）以二进制形式表示，然后从高位到低位依次处理
- 二进制的第 n 个位就对应了二叉树的第 n 层
- 如果该位是1，进入左子树，是0则进入右子树（人为约定，可以改变）
- 全部位都处理完后，这个 Node ID 就对应了二叉树上的某个叶子

### 距离与异或

Kademlia 中，根据当前节点的 Node ID 与它保存的其他 peer 节点 Node ID 的匹配的最多的前缀 bit 个数来构建一颗二叉树，这里前缀匹配的 bit 数也叫 LCP（Longest Common Prefix）。比如，当前节点为 1101，与 1000 的前缀匹配的最高位之后从第二位开始就不匹配了，其 LCP 就是 1。Kademlia 中根据 LCP 来划分子树。当前节点的每个 LCP 都是一个子树。也可以这么理解，如果两个节点共有的祖先节点少(高位相异)，它们的距离就远；反之，如果共有的祖先节点多(高位相同)，它们的距离就近。

假设当前节点 ID 是 0011，可以被划分为 LCP = 3（none/）, 2（0/）, 1（00/）, 0（001/） 一共 4 个子树：

[![RXD7Zt.md.png](https://z3.ax1x.com/2021/07/08/RXD7Zt.md.png)](https://imgtu.com/i/RXD7Zt)

对于任意一个给定节点，我们将二叉树从根节点开始不断向下分成一系列不包含该节点的子树。最高的子树由不包含该节点的二叉树的一半组成，下一个子树又由不包含该节点的剩余树的一半组成，以此类推。如果这个二叉树的高度为 m + 1, 我们最终会得到 m 个子树。

### K桶与路由表

每个子树就是一个K桶，对于 160 bit 空间的 Node ID 一共有160个子树即160个K桶（参数Keyspace = 160 bit）。每个K桶可以通过 XOR 的结果来索引。子树中包含的叶节点数量被设置为最多k个，k就是每个K桶可以存多少个节点（常为20，Mainline中为8）。

[![RXfT10.png](https://z3.ax1x.com/2021/07/08/RXfT10.png)](https://imgtu.com/i/RXfT10)

在每个子树中任取 k 个节点，形成 m 个K桶，这 m 个 k 桶就是 Kademlia 节点的路由表。我们定义最小子树中取得的节点为第 0 个 k 桶，次小的子树中取得的节点为第 1 个 k 桶，以此类推。对于每个 0⩽i<m，第 i 个K桶中节点与当前节点的距离总是在区间[2^i, 2^(i+1))之内。以 m = 3, k = 2 时节点 101 的K桶为例：

[![RX6vt0.md.png](https://z3.ax1x.com/2021/07/08/RX6vt0.md.png)](https://imgtu.com/i/RX6vt0)

再以下图为例：

[![RXRHCq.png](https://z3.ax1x.com/2021/07/08/RXRHCq.png)](https://imgtu.com/i/RXRHCq)

对于Node 0010，Node 0000存储过程如下：

- 距离 = 0010 ⊕ 0000 = 0010 = 2
- 距离在区间[2^i, 2^(i+1)) (i = 1)内，即2~3，所以Node 0000应放在K-bucket 1里

也可以通过LCP判断，看异或的结果的最高非零位：

- 0011和0010，前3位匹配，异或最高非零位为0，放在bucket0
- 0000/0001和0010，前2位匹配，异或最高非零位为1，放在bucket1
- 0100/0110/0101/0111和0010，前1位匹配，异或最高非零位为2，放在bucket2

# Algorithm

## Message

The Kademlia protocol consists of four RPC calls: PING, STORE, FIND_NODE, FIND_VALUE.

- PING message --- used to test if the node is still online
- STORE message --- to store a key-value pair in a node
- FIND_NODE message --- the recipient of the message request will return the k nodes which are closest to the requested key value in its bucket
- FIND_VALUE message --- Same as FIND_NODE, but when the recipient of the request has the key requested by the requester, it will return the value of the corresponding key.

Each RPC message contains a random value added by the initiator, which ensures that the response message is received in a way that matches the request message sent earlier and prevents address forgery.

A more specific implementation can be found in the KRPC protocol in Bittorrent's Mainline DHT, which is a simple RPC structure consisting of bencode encoding, using UDP. It contains 3 message types: request/reply/error and four types of requests.

- PING --- used to test if the node is still online, to assist in routing table updates
- ANNOUNCE_PEER(STORE) --- Notify other nodes to start downloading a resource themselves, `announce_peer` carries the token in the `get_peer` response message
- FIND_NODE --- used to find a node, to get its address information
- GET_PEERS(FIND_VALUE) --- a list of peers corresponding to the resource, obtained through the resource's infohash

## Look-up

The most important process that a node needs to implement in Kademlia is to find the k nodes closest to it based on a node ID, this process is the node lookup, which is mainly done using recursion.

As mentioned before, the basic operation related to the node storage process is the `FIND_NODE` operation, which accepts a Key as an argument and returns the k nearest nodes to the Key that the current node knows. The process of finding the k nearest nodes based on K buckets is as follows: first find the distance d between the Key and the current node; the distance between the node in the i-th K bucket and the current node is in the interval [2^i, 2^(i+1)), these intervals do not overlap each other, and the node in the K bucket where d falls in the interval is the nearest node to the Key. If there are less than k nodes in this K-bucket, the node is taken in the next K-bucket to replenish it, and if it is still not enough, take it in the next K-bucket again. If the sum of all the nodes in this node's K buckets is less than k, it returns all the nodes it knows.

The node lookup is then performed. Finding the nearest k nodes in the entire network given a Key is a recursive process: the starting node needed for the lookup first takes α nodes from the non-empty K bucket closest to the target node Node ID (if there are less than α nodes in the K bucket, the full α nodes are taken from the other K buckets). The whole process is that the initial node calls its own `FIND_NODE` and finds k nodes that it knows are closest to the Key. Next, we take α nearest nodes among these k nodes and request them to perform `FIND_NODE` for the Key (α is a system-level constant to set the number of simultaneous requests).

## Routing Table Maintenance

### Binary Tree Splitting

For each node, the entire binary tree can be split into up to 160 subtrees according to its own perspective. The rule of splitting is: start from the root node and split the subtree that does not contain itself; then split the second subtree that does not contain itself in the remaining subtrees; and so on, until finally only itself remains. For each node, when it finishes splitting the subtree with its own view, it will get n subtrees; for each subtree, if it knows a node inside, then it can use these n nodes for recursive routing to reach any node in the whole binary tree.

The prefix tree (Tire) is used in the Mainline DHT, but is slightly different. When inserting a key in a Trie tree, we have to compare each char of the key with the path in the Trie, and when it does not match, it will split into a subtree immediately. However, in Mainline DHT, when there is inconsistency, there is no immediate splitting, but a bucket of length k. Two cases are discussed：

- If the bucket length is less than k, just insert the bucket directly
- If the bucket length is greater than or equal to k, discuss it in another two cases:
  - The first case is that the current path is the prefix of the node Node ID (note that it is not the key to be inserted, but its own Node ID), then split, the key of the left and right subtrees are 0 and 1, and the nodes in the current bucket are divided into the bucket of the corresponding subtree according to their current char value
  - The second case is that the current path is not a prefix of the Node ID of the node, in this case, the key is dropped directly

### Routing Table's Change

The routing table is a binary tree with leaf nodes as K-buckets, and the set of all K-buckets covers the entire 160 bit space without overlap. The nodes in the routing table are dynamically allocated on demand. In the initial state, node u has only one node in the routing table, and one K-bucket covers the entire Node ID space. When u gets a new neighboring node, it will try to insert it into the appropriate K bucket based on the distance to the new neighboring node. The same as the subtree splitting above, the rules for insertion are as follows:

- If the K bucket is not full, the new neighboring node will be inserted directly
- If the K bucket is full.
  - If the range of the K bucket includes u's own Node ID, the K bucket will be split in two and the Node ID in the original K bucket will be reassigned to the new K bucket and then the insertion will be attempted again
  - If the range of the K bucket does not include u's own Node ID, the new neighboring node will be discarded directly
    - Problems can arise in highly unbalanced binary trees, assuming u is the only node with a Node ID starting with 000 and there are more than k nodes with IDs starting with 001 v1,v2...vk...vn. For each node v's routing table, u will be For each node v, u is inserted into an empty k-bucket. u's bucket update is only notified to k of all v's recorded in u's routing table
    - To avoid that the remaining v's do not get u's bucket update information, the nodes in the Kad are additionally split to save all valid nodes over k, even if not because the K bucket includes its own Node ID

[![RzZeat.md.png](https://z3.ax1x.com/2021/07/09/RzZeat.md.png)](https://imgtu.com/i/RzZeat)

## K-Bucket  Maintenance

### Refresh K-Bucket

When a node receives any request or reply message from another node, it updates the K bucket according to the sender's node ID. The rule is as follows.

- The nodes in each bucket are sorted in reverse order of the last contact time

- If the sending node already exists in the receiver's K bucket
  - The receiver moves the sender node to the end of the corresponding K bucket
- If the sending node is not in the receiver's K bucket
  - If the number of nodes in the K bucket is less than k, the sending node is inserted directly to the end of the K bucket
  - If the K bucket is full
    - If the least recent active node cannot ping through, remove the node and insert the sender node to the end of the K bucket
    - If the least active node can ping through, move the node to the tail and discard the sending node

The K bucket follows the Least Recently Used (LRU) elimination algorithm, where the least recently active nodes are ranked at the head of the K bucket and the most recently active nodes are ranked at the tail of the K bucket, which ensures that any node joining or leaving does not affect the overall network.

### Join the Network

In order to join the network, a node u has to be associated with a node w that already exists in the network. u inserts w into the appropriate K bucket, then u performs a node lookup on its own Node ID, and finally u contacts a node further away from its neighbors and updates the corresponding K bucket. During the refresh process, u constructs its own K bucket and also inserts itself into the K buckets of other nodes.

When a node joins, in addition to constructing a K bucket, it should also fetch the resources for which this node is responsible. at regular intervals in Kad, all nodes perform a post operation on the resources they own; in addition at regular intervals nodes discard resources that have not received a post message during this time. In this way, new nodes receive the resources they are responsible for, while the resources are always kept in the hands of the k nodes closest to them. Node exiting in Kad is not like the Chord algorithm, where nodes can exit without doing anything due to the k-bucket refresh and resource reissue mechanism.

# 算法

## 消息

Kademlia协议由四个 RPC 调用组成：PING, STORE, FIND_NODE, FIND_VALUE。

- PING消息---用来测试节点是否仍然在线
- STORE消息---在某个节点中存储一个键值对
- FIND_NODE消息---消息请求的接收者将返回自己桶中离请求键值最近的k个节点
- FIND_VALUE消息---与FIND_NODE一样，不过当请求的接收者存有请求者所请求的键的时候，它将返回相应键的值。

每一个RPC消息中都包含一个发起者加入的随机值，这一点确保响应消息在收到的时候能够与前面发送的请求消息匹配并防止地址伪造。

更具体的实现可以参考Bittorrent的Mainline DHT中的KRPC协议，它是由bencode编码组成的一个简单的RPC结构，使用 UDP 报文发送。它包含3种消息类型：请求/回复/错误。以及四种请求：

- PING---用来测试节点是否仍然在线,辅助路由表的更新
- ANNOUNCE_PEER(STORE)---通知其他节点自己开始下载某个资源，`announce_peer`中会携带`get_peer`回应消息里的token
- FIND_NODE---用于查找某个节点,以获得其地址信息
- GET_PEERS(FIND_VALUE)---与通过资源的infohash获得资源对应的peer列表

## 查找节点

Kademlia中节点需要实现的最重要的过程就是根据一个节点 ID 找到与它最近的 k 个节点，这个过程就是节点的查找，其中主要使用递归完成。

前文提过节点的储存过程，与之相关的基础操作是 `FIND_NODE` 操作，它接受一个 Key 作为参数，返回当前节点所知道的 k 个距离这个 Key 最近的节点。基于K桶找到这 k 个最近的节点的过程如下：先求出这个 Key 与当前节点的距离 d；第 i 个K桶中节点与当前节点的距离在区间[2^i, 2^(i+1))内，这些区间不会互相重叠，d 落在的区间所属的K桶中的节点就是距离这个 Key 最近的节点。如果这个K桶中的节点不足 k 个, 则在后一个K桶中取节点补充，如果还不够就再在后一个K桶中取。如果这个节点所有的K桶中的节点数之和都不足 k 个，就返回它所知道的所有节点。

随后进行节点查找，给定一个 Key 找出整个网络中距离它最近的 k 个节点是一个递归过程：由查找需要的起始节点先从离目标节点 Node ID 最近的非空K桶中取出 α 个节点（如果K桶中节点不足 α 个，则从其他K桶中取满 α 个）。整个过程就是初始节点调用自己的 `FIND_NODE`，找到 k 个它所知的距离 Key 最近的节点。接下来我们在这 k 个节点中取 α 个最近的节点，同时请求它们为 Key 执行 `FIND_NODE`（α 为系统级常量, 用于设置同时请求个数）。

多说无益，下面看下具体的例子，其核心思想就是每一次找都找最接近的。假设Node ID 0010要寻找Node ID 1110，但在0010节点保存的路由表中的Bucket里没有储存1110节点。

1. 0010 ⊕ 1110 = 1101 = 12，在 [8,16) 区间即 0010 的bucket 3
2. 向 bucket 3 中的节点依次发出查询请求，先从其中最前的 8 即 0010 ⊕ 1010 = 1000开始（设置 α = 3，则可以同时询问3个节点）
3. 1010 ⊕ 1110 = 0100 = 4，在 [4,7) 区间即 1010 的bucket 2，若无记录，继续向 bucket 2 中的节点发出查询请求
4. 设置 α = 3，向1111、1100、1101同时查询。假设1101  ⊕ 1110 = 0011 = 3在 [2,4)区间有1110记录，那么就找到了1110节点
5. 整个节点查找过程是不断收敛的，复杂度是O(log(n))



## 路由表维护

### 二叉树拆分

对每一个节点，都可以按照自己的视角对整个二叉树进行拆分成最多160个子树。拆分的规则是：先从根节点开始，把不包含自己的那个子树拆分出来；然后在剩下的子树再拆分不包含自己的第二层子树；以此类推，直到最后只剩下自己。对于每一个节点而言，当它以自己的视角完成子树拆分后，会得到 n 个子树；对于每个子树，如果它都能知道里面的一个节点，那么它就可以利用这 n 个节点进行递归路由，从而到达整个二叉树的任何一个节点。

Mainline DHT中使用前缀树（Tire），但是与Trie树又稍微有所不同。在Trie树里插入一个key时，我们要比对key的每一个char和Trie里边路径，当不一致时，会立刻分裂成一个子树。但是Mainline DHT中，当不一致时，不会立刻分裂，而是有一个长度为k的bucket。分两种情况讨论：

- 如果bucket长度小于k，直接插入bucket即可
- 如果bucket长度大于或等于k，分两种情况讨论：
  - 第一种情况是当前的路径是该节点Node ID（注意不是要插入的key，是自己的Node ID）的前缀，那么就分裂，左右子树的key分别是0和1，并且把当前bucket中的节点根据他们的当前char值分到相应的子树的bucket里边。
  - 第二种情况是当前路径不是该节点Node ID的前缀，这种情况下，直接把这个key丢掉。

### 路由表演变

路由表是一棵叶子节点为K桶的二叉树，所有的K桶集合无重叠地覆盖了整个 160 bit 空间。路由表中的节点是按需动态分配的，初始状态下，节点 u 的路由表只有一个节点，一个K桶覆盖了整个 Node ID 空间。当 u 得到了一个新的相邻节点时，它将根据与新的相邻节点的距离，尝试将其插入到合适的K桶中。和上面子树拆分一样，插入的规则如下：

- 如果K桶未满，新的相邻节点就会被直接插入
- 如果K桶满了：
  - 如果K桶的范围包括了 u 自身的 Node ID，则K桶将会一分为二，原K桶中的 Node ID 重新分配到新的K桶中，然后再尝试插入
  - 如果K桶的范围不包括 u 自身的 Node ID，新的相邻节点将直接被丢弃
    - 高度不平衡的二叉树中可能产生问题，假设 u 是唯一一个 Node ID 以 000 开头的节点，同时有超过 k 个 ID 以 001 开头的节点 v1,v2…vk…vn。对于每个节点 v 的路由表，u 都将会被插入到一个空K桶中。u 的桶更新只会通知到 u 的路由表所记录的所有 v 中的 k 个。
    - 为了避免剩余的 v 无法得到 u 的桶更新信息，Kad中节点通过进行额外的拆分以保存了超过 k 个的所有有效的节点，哪怕不是因为K桶中包括了自身的 Node ID。

[![RzZeat.md.png](https://z3.ax1x.com/2021/07/09/RzZeat.md.png)](https://imgtu.com/i/RzZeat)

## K桶维护

### K桶更新

当一个节点收到任一来自其他节点的请求或者回复消息，它会根据发送者的节点 ID 更新K桶。规则如下：

- 每个bucket里的节点都按最后一次接触的时间倒序排列

- 如果发送节点已经存在接收方的K桶中：
  - 接收方将发送节点移动到相应K桶的尾部
- 如果发送节点不在接收方的K桶中：
  - 如果K桶中节点数量少于 k 个，则直接将发送节点插入至K桶尾部
  - 如果K桶已满：
    - 如果最近最少活跃节点不能 ping 通，则移除该节点，然后将发送节点插入至K桶尾部
    - 如果最近最少活跃节点可以 ping 通，则将该节点移动到尾部，然后丢弃发送节点

K桶遵循最近最少使用(Least Recently Used, LRU)淘汰算法，最近最少活跃的节点排在K桶的头部，最近最多活跃的节点排在K桶尾部，该机制保证了任意节点加入和离开都不影响整体网络。

### 加入网络

为了加入网络，一个节点 u 必须要与一个已存在在网络中的节点 w 有联系。u 将 w 插入到合适的K桶中，随后 u 对自己的 Node ID 进行一次节点查询，最后 u 会联系到离它邻居更远的节点，然后更新相应的K桶。在刷新过程中，u 构建自己的K桶同时也将自己插入到其他节点的K桶中。

节点加入时除了构建K桶之外，还应该取回这个节点应负责的资源。Kademlia中每隔一段时间，所有的节点都对其拥有的资源执行一次发布操作；此外每隔一段时间节点就会丢弃这段时间内未收到发布消息的资源。这样新节点就能收到自己须负责的资源，同时资源总能保持被 k 个距离它最近的节点负责。Kad的节点退出则不似Chord算法，由于具有K桶刷新和资源重发的机制，节点不需要做任何操作即可退出。



**Reference/参考**: 

1. [Distributed hash table](https://en.wikipedia.org/wiki/Distributed_hash_table)
2. [DHT 网络之 Kademlia 算法](https://0ranga.com/2018/11/08/dht-kademlia/)
3. [DHT 分布式哈希表](https://colobu.com/2018/03/26/distributed-hash-table/)
4. [易懂分布式 Kademlia算法](https://www.jianshu.com/p/f2c31e632f1d)
5. [P2P 网络核心技术：Kademlia 协议](https://zhuanlan.zhihu.com/p/40286711)
6. [DHT Protocol：BitTorrent DHT 协议中文翻译](https://justjavac.com/other/2015/02/01/bittorrent-dht-protocol.html)



